{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS FLOW CLASSES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import scipy.stats as ttest_ind\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,cross_val_predict\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "data=pd.read_csv(\"hmelq.csv\")\n",
    "class Loading_Data:\n",
    "    def __init__ (self,data):\n",
    "        self.data=data\n",
    "    def translate_to_dataframe(self):# dataset is converted to dataframe\n",
    "        return pd.DataFrame(self.data).head()# the first 5 observations of the data set are shown\n",
    "# Data Information\n",
    "class Information:\n",
    "    def __init__ (self,data):\n",
    "        self.data=data\n",
    "    def info_data(self):\n",
    "        print(self.data.info())    \n",
    "        print(self.data.dtypes)\n",
    "        print(self.data.shape)\n",
    "        print(self.data.columns)\n",
    "    def describe_missing_values(self):\n",
    "        print(self.data.isnull().values.any()) # Are there any missing observations in the dataset? If there is True; If there is no False returns\n",
    "        print(self.data.isnull().sum())# Prints the number of missing observations on the basis of variables\n",
    "    def select_dtypes_numeric(self):\n",
    "        df_numeric=self.data.select_dtypes(include=['float64','int64'])# numeric variables are selected\n",
    "        return df_numeric\n",
    "    def describe_data(self):# summary statistics information of numeric variables are accessed\n",
    "        df_numeric=self.data.select_dtypes(include=['float64','int64'])# numeric variables are selected\n",
    "        print(self.data.describe().T)\n",
    "    def select_dtypes_category(self):\n",
    "        df_category=self.data.select_dtypes(include=[\"object\"])# categorical variables are selected\n",
    "        print(df_category)\n",
    "        for i in df_category.columns:\n",
    "            print(self.data[i].value_counts()) # Prints the frequency information of categorical variables\n",
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "class Visualizer:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def msno_bar(self):\n",
    "        plt.figure(figsize=(6,5))\n",
    "        msno_bar = msno.bar(self.data,color='lightblue')\n",
    "        return msno_bar\n",
    "    def bar_plot(self,x=None,y=None,z = None):# Used to visualize barplot categorical variables\n",
    "        plt.figure(figsize=(6,5))\n",
    "        sns.barplot(x=x, y=y, hue=z, data=self.data)\n",
    "    def box_plot(self,x=None,y=None,z=None): # continuous variables are visualized with the help of cartridges\n",
    "        numeric_features=[x for x in data.columns if data[x].dtype!=\"object\"]\n",
    "        for i in data[numeric_features].columns:\n",
    "            plt.figure(figsize=(6,5))\n",
    "            plt.title(i)\n",
    "            sns.boxplot(data=data[i])\n",
    "    def hist_plot(self):\n",
    "        df_numeric=self.data.select_dtypes(include=['float64','int64'])\n",
    "        for i in df_numeric.columns:\n",
    "            plt.figure()\n",
    "            plt.hist(df_numeric[i],bins=100,color=\"orange\")\n",
    "            plt.title(\"Histogram of \"+ i)\n",
    "    def dist_plot(self,x=None,y=None,z=None):\n",
    "        df_numeric=self.data.select_dtypes(include=['float64','int64'])\n",
    "        df_numeric=df_numeric.dropna()\n",
    "        for i in  df_numeric.columns:\n",
    "            plt.figure()\n",
    "            sns.distplot(np.array(df_numeric[i]),hist=False,kde=True,color=\"g\")\n",
    "            plt.title(\"Distplot  of \"+ i)\n",
    "    def reg_plot(self):\n",
    "        plt.figure(figsize=(16, 7))\n",
    "        df_numeric=self.data.select_dtypes(include=['float64','int64'])\n",
    "        for i, column in enumerate(df_numeric.select_dtypes(exclude=['object']).columns[1:], 1):\n",
    "            plt.subplot(2, 5, i)\n",
    "            randNorm = np.random.normal(np.mean(df_numeric[column]), np.std(df_numeric[column]), len(df_numeric[column]))\n",
    "            sns.regplot(np.sort(randNorm), np.sort(df_numeric[column]))\n",
    "            plt.xlabel(f'{column}')\n",
    "    def count_plot(self,x=None,y=None,z=None):\n",
    "        plt.figure(figsize=(6,5))\n",
    "        sns.countplot(x=x, y=y, hue=z, data=self.data)\n",
    "    def correlation(self):\n",
    "        fig,ax = plt.subplots(figsize=(10, 10))\n",
    "        sns.heatmap(data.corr(), ax=ax, annot=True, \n",
    "        linewidths=0.05, fmt= '.2f',cmap=\"Blues\")\n",
    "        plt.show()\n",
    "    def scatter_plot(self,x=None,y=None,z=None):\n",
    "        return sns.scatterplot(x=x,y=y,data=self.data)\n",
    "    def lm_plot(self,x=None,y=None,z=None,w=None,r=None):\n",
    "        return sns.lmplot(x=x, y=y, hue=z,col=w,row=r, data=self.data)\n",
    "    def swarm_plot(self,x=None,y=None,z=None):\n",
    "        return sns.swarmplot(x=x, y=y,hue=z, data=self.data)\n",
    "    def line_plot(self,x=None,y=None,z=None):\n",
    "        return sns.lineplot(x=x,y=y,hue=z,data=self.data)\n",
    "    def pair_plot(self,x=None,y=None,z=None,w=None):\n",
    "        return sns.pairplot(self.data,hue=z)\n",
    "    def cross_tab(self,x=None,y=None,n=None):\n",
    "        numeric_features=[x for x in data.columns if data[x].dtype!=\"object\"]\n",
    "        for i in numeric_features.columns:\n",
    "            return pd.crosstab(self.data[i],self.data[i],normalize=n).style.background_gradient(cmap=\"summer_r\")\n",
    "        \n",
    "# Performing Hypothesis Testing\n",
    "class HypothesisTesting:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def normality_assumption(self):# normality assumption is realized by shapiro wilks test\n",
    "        df_numeric=self.data.select_dtypes(include=['float64','int64'])\n",
    "        for i in df_numeric.columns:\n",
    "                df_new = df_numeric.dropna(subset=[i])\n",
    "                stat, p = stats.shapiro(df_new[i])\n",
    "                print(\"Statistics:%3.3f, p=%.3f \" % (stat,p))\n",
    "                alpha = 0.05\n",
    "                if p>alpha:\n",
    "                    print(i,\" için Orneklem Normal (Gaussian) Dagilimdan gelmektedir (Fail to Reject H0)\")\n",
    "                else:\n",
    "                    print(i,\" için Orneklem Normal (Gaussian) Dagilimdan gelmemektedir (reject H0)\")\n",
    "        print(\"*****************************************************************************************\")\n",
    "    def assumption_of_variance_homogeneity(self,variable=None,x=None,y=None):#assumption of variance homogeneity is realized by levene test\n",
    "        grps=pd.unique(data[variable].values)\n",
    "        df_numeric=self.data.select_dtypes(include=['float64','int64'])\n",
    "        for i in df_numeric.columns:\n",
    "            for j in grps:\n",
    "                df_new = data.dropna(subset=[i])\n",
    "                stat, p = stats.levene(df_new[i][data[variable]==x],df_new[i][data[variable]==y])\n",
    "                print(\"Statistics:%3.3f, p=%.3f \" % (stat,p))\n",
    "                alpha = 0.05\n",
    "                if p>alpha:\n",
    "                    print(i,j,\" için varyans homojendir. (Fail to Reject H0)\")\n",
    "                else:\n",
    "                    print(i,j,\" için varyans homojen degildir. (reject H0)\")\n",
    "        print(\"*****************************************************************************************\")\n",
    "\n",
    "    def two_independent_samples_t_test(self,variable=None,x=None,y=None):\n",
    "        df_numeric=self.data.select_dtypes(include=['float64','int64'])\n",
    "        for i in df_numeric.columns:\n",
    "            df_new= self.data.dropna(subset=[i])\n",
    "            bad_risk=df_new[df_new[variable]==x][i]\n",
    "            good_risk=df_new[df_new[variable]==y][i]\n",
    "            t, p = stats.ttest_ind(bad_risk, good_risk, equal_var=False)\n",
    "            print(\"ttest_ind: i=%s t = %g  p = %g\" % (i,t, p))\n",
    "            alpha = 0.05\n",
    "            if p>alpha:\n",
    "                print(i,\" ile  bad değişkeni arasında istatistiksel olarak anlamlı bir fark vardır.(Fail to Reject H0)\")\n",
    "            else:\n",
    "                print(i,\" ile  bad değişkeni arasında istatistiksel olarak anlamlı bir fark yoktur.(reject H0)\")\n",
    "        print(\"*****************************************************************************************\")\n",
    "    def chi_square_t_test(self,x=None,y=None):\n",
    "        data_cross_tab=pd.crosstab(index=data[x],columns=data[y])\n",
    "        chi2,p,dof,expected=stats.chi2_contingency(data_cross_tab)\n",
    "        results=[[\"Item\",\"Value\"],\n",
    "                 [\"Chi-Square Test\",chi2],\n",
    "                 [\"p - value\",p]]\n",
    "        print(\"Chi-Square Test =%g p=%g\" %(chi2,p))\n",
    "        alpha = 0.05\n",
    "        if p>alpha:\n",
    "            print(x,\"ve\",y,\" degiskenleri birbirinden bağımsızdır.(Fail to Reject H0)\")\n",
    "        else:\n",
    "            print(x,\"ve\",y,\" degiskenleri birbirinden bağımsız değildir(reject H0)\")\n",
    "        print(\"*****************************************************************************************\")\n",
    "        \n",
    "# Data Preprocessing\n",
    "class PreprocessStrategy:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def fill_missing_value(self):\n",
    "        data=self.data.dropna()\n",
    "        return data.head()\n",
    "    def fill_missing_value_with_mean(self):#fill in missing values in all variables with mean\n",
    "        return self.data.apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "    def fill_missing_value_with_median(self):#fill in missing values in all variables with median\n",
    "        return self.data.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "    def normalization(self):# converts variable values from 0 to 1\n",
    "        return preprocessing.normalize(self.data)\n",
    "    def one_hot_dummy_variable(self,variable=None):#It can be used to convert categorical variable to continuous variable. As a result, awareness among classes will be preserved.\n",
    "        df_one_hot=self.data.copy()\n",
    "        return pd.get_dummies(df_one_hot,columns=[variable],prefix=[variable]).head()\n",
    "    def label_encoder(self,new_variable_name=None,categorical_variable_to_converted=None):# Performs conversions by the number of classes available\n",
    "        lbe=preprocessing.LabelEncoder()\n",
    "        data[new_variable_name]=lbe.fit_transform(data[categorical_variable_to_converted])\n",
    "        return data[new_variable_name]\n",
    "    def standardization(self):#a standardization is performed with an average of 0 standard deviations of one\n",
    "        df_standardization=preprocessing.scale(self.data)\n",
    "        return df_standardization\n",
    "    def min_max_transformation(self,x=None,y=None):#Used to convert the values of a variable between two ranges that we want\n",
    "        scaler=preprocessing.MinMaxScaler(feature_range=(x,y))\n",
    "        return scaler.fit_transform(self.data)\n",
    "    def binarize_transformation(self,threshold=None):#Converts the variable's values to 0 or 1 according to a certain threshold value\n",
    "        binarizer=preprocessing.Binarizer(threshold=threshold).fit(self.data)\n",
    "        return binarizer.transform(self.data)\n",
    "        \n",
    "        \n",
    "# Data Modelling ,Performance/Evaluation metrics of the models\n",
    "class GridSearchHelper():# model fit, model predict and model results are performed in this section\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def dataset_split(self,X_train=None,X_test=None,y_train=None,y_test=None):\n",
    "        X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.20,random_state=42)\n",
    "        return X_train,X_test,y_train,y_test\n",
    "    def linear_regresyon(self,X_train=None,X_test=None,y_test=None,y_train=None):\n",
    "        #X= df[[x]]# x independent variable\n",
    "        #y=df[[y]] # y dependent variable \n",
    "        lm=LinearRegression()\n",
    "        model=lm.fit(X_train,y_train)# model object created\n",
    "        return model\n",
    "    def pca(self,X_train=None,X_test=None,y_test=None,y_train=None):\n",
    "        pca =PCA()\n",
    "        X_reduced_test= pca.fit_transform(scale(X_test))\n",
    "        print(np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)[0:5])\n",
    "        lm=LinearRegression()\n",
    "        y_train=y_train.fillna(y_train.mean())\n",
    "        model=lm.fit(X_reduced_test,y_train)\n",
    "        return model\n",
    "    def logistic_regresyon(self,X_train=None,X_test=None,y_test=None,y_train=None,solver=None):\n",
    "        loj=LogisticRegression(solver=solver)\n",
    "        model=loj.fit(X_train,y_train)\n",
    "        return model\n",
    "    def fit_predict(self,X_test=None):\n",
    "        y_pred=model.predict(X_test)\n",
    "        print(y_pred)\n",
    "    def show_evaluation_metrics_and_result_regression_model(self,X_test=None,y_test=None):\n",
    "        print(model.intercept_)\n",
    "        print(model.coef_)\n",
    "        print(r2_score(y_test,y_pred))\n",
    "        print(np.sqrt(mean_squared_error(y_test,model.predict(X_test))))#test error on the model\n",
    "        print(np.sqrt(- cross_val_score(model,\n",
    "                X_test,\n",
    "                y_test,\n",
    "                cv=10,\n",
    "                scoring=\"neg_mean_squared_error\")).mean())\n",
    "    def show_evaluation_metrics_and_result_classification_model(self,X_test=None,y_test=None):\n",
    "        print(accuracy_score(y_test,y_pred))\n",
    "        print(cross_val_score(loj_model,X_test,y_test,cv=10).mean())\n",
    "        print(classification_report(y_test,y_pred))\n",
    "    def roc_curve(self,X_test=None,y_test=None):\n",
    "        logit_roc_auc=roc_auc_score(y_test,loj_model.predict(X_test))\n",
    "        fpr,tpr,threshold=roc_curve(y_test,loj_model.predict_proba(X_test)[:,1])\n",
    "        plt.figure()\n",
    "        plt.plot(fpr,tpr,label='AUC( area =%0.2f)' % logit_roc_auc)\n",
    "        plt.plot([0,1],[0,1],'r--')\n",
    "        plt.xlim([0.0,1.0])\n",
    "        plt.ylim([0.0,1.05])\n",
    "        plt.xlabel('False Positive Oranı')\n",
    "        plt.ylabel('True Positive Oranı')\n",
    "        plt.title('ROC')\n",
    "        plt.show()\n",
    "    def visualization_residual(self,model=None):\n",
    "        return plt.plot(model.resid)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
